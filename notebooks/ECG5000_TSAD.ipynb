{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulzF6ZaiubO0",
        "outputId": "4c607505-773c-4a95-b017-8a36ae63402b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Aug 25 07:58:16 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8             12W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxnigvfw3gBe"
      },
      "source": [
        "#1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0LlLclnygzt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40xHYez405to",
        "outputId": "bb7a7568-b40c-474b-ec42-3e32cc615c4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fad5d193df0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set random seed\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTi1rTqy2M4t"
      },
      "source": [
        "# 2. Data loading and preprocessing\n",
        "\n",
        "The dataset contains 5,000 Time Series examples (obtained with ECG) with 140 timesteps. Each sequence corresponds to a single heartbeat from a single patient with congestive heart failure.\n",
        "\n",
        "The training set contains 500 samples, while the other 4500 is in the testing set. Both contains all 5 types of heartbeats (classes):\n",
        "\n",
        "* Normal (N)\n",
        "* R-on-T Premature Ventricular Contraction (R-on-T PVC)\n",
        "* Premature Ventricular Contraction (PVC)\n",
        "* Supra-ventricular Premature or Ectopic Beat (SP or EB)\n",
        "* Unclassified Beat (UB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV3hGLdY2nTD"
      },
      "source": [
        "Download the dataset (Already uploaded to google drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlG3Lg5G3eE_",
        "outputId": "926c2a34-6966-4835-b238-8abc1e431584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fIKPykPzZ5pky8B59OYBtH7pzBORuZy3\n",
            "To: /content/ECG5000.zip\n",
            "100% 10.6M/10.6M [00:00<00:00, 20.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1fIKPykPzZ5pky8B59OYBtH7pzBORuZy3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exQh0ui-4AjA",
        "outputId": "fe974369-1429-46c8-e567-746e73bbb204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace ECG5000.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!unzip -qq ECG5000.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqx4Dneb4BiS",
        "outputId": "1d5df750-7489-46e0-c826-7317c73391e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ni5bQOT4HQo",
        "outputId": "6d847fea-9554-459c-b56c-79a3a059f100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All data shape: (5000, 140)\n",
            "[1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "train_path = f\"/content/ECG5000_TRAIN.txt\"\n",
        "test_path = f\"/content/ECG5000_TEST.txt\"\n",
        "\n",
        "# Load the datasets\n",
        "train_data = np.loadtxt(train_path)\n",
        "test_data = np.loadtxt(test_path)\n",
        "\n",
        "all_data = np.vstack([train_data, test_data])\n",
        "\n",
        "# Split into features (X) and labels (y)\n",
        "X_all, y_all = all_data[:, 1:], all_data[:, 0].astype(int)\n",
        "\n",
        "print(\"All data shape:\", X_all.shape)\n",
        "print(np.unique(y_all))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oGqXWEeg_z4"
      },
      "source": [
        "After that, we'll separate normal vs anomalous sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf2xhISNg_Z6",
        "outputId": "1a8e4caf-e02d-48f1-cbcb-bbb6b3f2f963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal data shape: (2919, 140)\n",
            "Anomaly data shape: (2081, 140)\n"
          ]
        }
      ],
      "source": [
        "class_names = ['Normal', 'R-on-T PVC', 'PVC', 'SP or EB', 'UB']\n",
        "CLASS_NORMAL = 1\n",
        "\n",
        "X_normal = X_all[y_all==CLASS_NORMAL]\n",
        "X_anomaly = X_all[y_all!=CLASS_NORMAL]\n",
        "\n",
        "print(\"Normal data shape:\", X_normal.shape)\n",
        "print(\"Anomaly data shape:\", X_anomaly.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rHrT0hChcov"
      },
      "source": [
        "We'll be training only normal sequences. The majority of the normals will be used for training, and we'll set aside part of it for validation and testing. The testing set will be used in conjunction with the anomalous sequences later when we are detecting anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRlnFDa37uHm",
        "outputId": "c4bc1161-cd8c-4a4c-9650-9ad5bc41d9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train normals (1751, 140)\n",
            "Val normals (584, 140)\n",
            "Test normals (584, 140)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val = train_test_split(\n",
        "    X_normal,\n",
        "    test_size = 0.4,\n",
        "    random_state = RANDOM_SEED\n",
        ")\n",
        "\n",
        "X_val, X_test_normals = train_test_split(\n",
        "    X_val,\n",
        "    test_size = 0.5,\n",
        "    random_state = RANDOM_SEED\n",
        ")\n",
        "\n",
        "print(\"Train normals\", X_train.shape)\n",
        "print(\"Val normals\", X_val.shape)\n",
        "print(\"Test normals\", X_test_normals.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCuD2cKiqbSc",
        "outputId": "e272411e-e909-45fa-e844-23f5d9bc8b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: (2665, 140) (4746,)\n"
          ]
        }
      ],
      "source": [
        "# Test = all anomalies + some normals\n",
        "X_test = np.vstack([X_test_normals, X_anomaly])\n",
        "y_test = np.hstack([\n",
        "    np.zeros(len(X_test), dtype=int),   # normals = 0\n",
        "    np.ones(len(X_anomaly), dtype=int)    # anomalies = 1\n",
        "])\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtckq1aYlmgw"
      },
      "source": [
        "Since ECG signals vary in amplitude and offset (e.g. , patient differences, electrode placement), data normalisation is necessary to prevent the model from wasting capacity to mdoel absolute scale instead of waveform shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_MdvOPHj5fQ",
        "outputId": "3da17e9a-477d-4f9d-d7cc-7596d376025f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (1751, 140)\n",
            "Val shape: (584, 140)\n",
            "Test shape: (2665, 140)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Val shape:\", X_val.shape)\n",
        "print(\"Test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNbynzxGmAL_"
      },
      "source": [
        "We'll then need to reshape the datasets into a shape of (N, n_len, features_num) so that they can be used with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNovt0wlmFuV",
        "outputId": "e0ce3452-15a9-4c4a-ffbf-ae68f63d5c09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (1751, 140, 1)\n",
            "Val shape: (584, 140, 1)\n",
            "Test shape: (2665, 140, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train[..., None]\n",
        "X_val = X_val[..., None]\n",
        "X_test = X_test[..., None]\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Val shape:\", X_val.shape)\n",
        "print(\"Test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTbLjsHrottZ"
      },
      "source": [
        "We'll then need to wrap these dataset into DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "Cl7Yoz3koy-S",
        "outputId": "938c213c-9fdd-4ba5-fef6-ce2ee01b7ec8"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Size mismatch between tensors",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-88486043.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX_train_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_val_loader\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mto_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX_test_loader\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mto_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-88486043.py\u001b[0m in \u001b[0;36mto_loader\u001b[0;34m(X, y, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         assert all(\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         ), \"Size mismatch between tensors\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Size mismatch between tensors"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def to_loader(X, y=None, batch_size=32, shuffle=False):\n",
        "    X_t = torch.tensor(X, dtype=torch.float32)\n",
        "    if y is None:\n",
        "        ds = TensorDataset(X_t)\n",
        "    else:\n",
        "        y_t = torch.tensor(y, dtype=torch.long)\n",
        "        ds = TensorDataset(X_t, y_t)\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "X_train_loader = to_loader(X_train,  batch_size=128, shuffle=True)\n",
        "X_val_loader   = to_loader(X_val, batch_size=128)\n",
        "X_test_loader  = to_loader(X_test, y_test, batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5RMmhqjIOGr"
      },
      "source": [
        "#5. LSTM-AE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxW9mg_LhpU8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMAE(nn.Module):\n",
        "    def __init__(self, seq_len=140, feat_dim=1, hidden_size=64, latent_dim=16, num_layers=2, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        # ---- Encoder ----\n",
        "        self.encoder_lstm = nn.LSTM(\n",
        "            input_size=feat_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "        self.to_latent = nn.Linear(hidden_size, latent_dim)\n",
        "\n",
        "        # ---- Decoder ----\n",
        "        self.decoder_lstm = nn.LSTM(\n",
        "            input_size=latent_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "        self.to_output = nn.Linear(hidden_size, feat_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        # x: (B, T, F)\n",
        "        _, (h_n, _) = self.encoder_lstm(x)   # take last hidden state\n",
        "        h_last = h_n[-1]                     # (B, H)\n",
        "        z = self.to_latent(h_last)           # (B, D)\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        # Repeat latent across time to reconstruct sequence\n",
        "        z_seq = z.unsqueeze(1).repeat(1, self.seq_len, 1)  # (B, T, D)\n",
        "        y, _ = self.decoder_lstm(z_seq)                    # (B, T, H)\n",
        "        x_hat = self.to_output(y)                          # (B, T, F)\n",
        "        return x_hat\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat, z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR2qa6XfrdzA"
      },
      "source": [
        "Model initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PGMKr82rdNA"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LSTMAE(\n",
        "    seq_len=140, feat_dim=1,\n",
        "    hidden_size=64, latent_dim=16,\n",
        "    num_layers=1, dropout=0.0\n",
        ").to(device)\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBabff0wrc_w"
      },
      "source": [
        "TRaining setup\n",
        "* Optimizer: Adam\n",
        "* Loss: MAE\n",
        "* Gradient clipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32_nD3wN1H4b"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    model.train(train)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for (xb,) in loader:            # train/val loaders yield only X\n",
        "        xb = xb.to(device)\n",
        "        x_hat, _ = model(xb)\n",
        "        loss = F.l1_loss(x_hat, xb)  # MAE loss\n",
        "\n",
        "        if train:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBt1SFSJ1w1C"
      },
      "source": [
        "Training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMGi5-jJ1wlr"
      },
      "outputs": [],
      "source": [
        "best_val, patience, bad_epochs = float(\"inf\"), 10, 0\n",
        "\n",
        "for epoch in range(200):\n",
        "    train_loss = run_epoch(X_train_loader, train=True)\n",
        "    val_loss   = run_epoch(X_val_loader, train=False)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: train={train_loss:.4f}, val={val_loss:.4f}\")\n",
        "\n",
        "    # If val_loss improves by 1e-5, adjust best_val and save model\n",
        "    if val_loss < best_val - 1e-5:\n",
        "        best_val, bad_epochs = val_loss, 0\n",
        "        torch.save(model.state_dict(), \"lstm_ae_best.pt\")\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "\n",
        "    # Trigger early stopping and\n",
        "    if bad_epochs >= patience:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ljlfVIn3p7h"
      },
      "source": [
        "Using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvXkue-W3pg_"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\"lstm_ae_best.pt\"))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    xb, _ = next(iter(X_test_loader))\n",
        "    xb = xb.to(device)\n",
        "    x_hat, z = model(xb)\n",
        "\n",
        "print(\"Input batch shape:\", xb.shape)\n",
        "print(\"Reconstruction shape:\", x_hat.shape)\n",
        "print(\"Latent shape:\", z.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGnW4EV35xR-"
      },
      "source": [
        "# Extract reconstruction error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDQAUgkf5zln"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_recon_errors(loader, model, device):\n",
        "    model.eval()\n",
        "    errors, labels = [], []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 2:   # (X, y) for test set\n",
        "            xb, yb = batch\n",
        "            labels.append(yb.numpy())\n",
        "        else:                 # (X,) for train/val (no labels)\n",
        "            xb = batch[0]\n",
        "\n",
        "        xb = xb.to(device)\n",
        "        x_hat, _ = model(xb)\n",
        "\n",
        "        # error per sample = mean abs diff across time/features\n",
        "        err = (x_hat - xb).abs().mean(dim=(1,2)).cpu().numpy()\n",
        "        errors.append(err)\n",
        "    errors = np.concatenate(errors)\n",
        "    labels = None if not labels else np.concatenate(labels)\n",
        "    return errors, labels\n",
        "\n",
        "train_errs, _        = get_recon_errors(X_train_loader, model, device)\n",
        "val_errs, _          = get_recon_errors(X_val_loader, model, device)\n",
        "test_errs, test_lbls = get_recon_errors(X_test_loader, model, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUnsQdyb6XRO"
      },
      "outputs": [],
      "source": [
        "thr = np.quantile(train_errs, 0.99)\n",
        "print(thr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v1_TUJw6ZRV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score, confusion_matrix\n",
        "\n",
        "preds = (test_errs > thr).astype(int)\n",
        "P, R, F1, _ = precision_recall_fscore_support(test_lbls, preds, average='binary', zero_division=0)\n",
        "roc  = roc_auc_score(test_lbls, test_errs)\n",
        "pr   = average_precision_score(test_lbls, test_errs)\n",
        "cm   = confusion_matrix(test_lbls, preds)\n",
        "\n",
        "print({\"precision\": P, \"recall\": R, \"f1\": F1, \"roc_auc\": roc, \"pr_auc\": pr})\n",
        "print(\"Confusion matrix:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQSzXkwyOX55"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Histograms\n",
        "plt.figure()\n",
        "plt.hist(train_errs, bins=50, alpha=0.6, label=\"train normals\")\n",
        "plt.hist(test_errs[test_lbls==0], bins=50, alpha=0.6, label=\"test normals\")\n",
        "plt.hist(test_errs[test_lbls==1], bins=50, alpha=0.6, label=\"test anomalies\")\n",
        "plt.axvline(thr, color='r', linestyle='--', label=f\"thr={thr:.4f}\")\n",
        "plt.legend(); plt.title(\"Reconstruction error distributions\"); plt.show()\n",
        "\n",
        "# PR & ROC curves\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "p, r, _ = precision_recall_curve(test_lbls, test_errs)\n",
        "fpr, tpr, _ = roc_curve(test_lbls, test_errs)\n",
        "plt.figure(); plt.plot(r, p); plt.title(\"PR curve\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.show()\n",
        "plt.figure(); plt.plot(fpr, tpr); plt.title(\"ROC curve\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.show()\n",
        "\n",
        "# Reconstruction overlays (pick one normal and one anomaly)\n",
        "import numpy as np\n",
        "def show_recon(i):\n",
        "    xb, yb = next(iter(test_loader))\n",
        "    xb = xb.to(device)\n",
        "    xh, _ = model(xb)\n",
        "    plt.figure()\n",
        "    plt.plot(xb[i].cpu().numpy().squeeze(), label=\"original\")\n",
        "    plt.plot(xh[i].cpu().numpy().squeeze(), label=\"reconstructed\")\n",
        "    plt.legend(); plt.title(f\"y={yb[i].item()}, err={float((xh[i]-xb[i]).abs().mean()):.4f}\")\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ecg500-tsad",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
